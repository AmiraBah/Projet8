{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import uniform, randint\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shap\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_test = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/application_test.csv', sep=',', encoding='ISO-8859-1')\n",
    "application_train = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/application_train.csv', sep=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_test[\"type_data\"]=\"test\"\n",
    "application_train[\"type_data\"]=\"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    # Exclure la colonne 'Type_data' des colonnes catégorielles\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col != 'type_data']\n",
    "    # Encodage one-hot pour les autres colonnes catégorielles\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    # Read data and merge\n",
    "    df = application_train.copy()\n",
    "    test_df = application_test.copy()\n",
    "\n",
    "    # Ensure 'TARGET' column exists in test data by filling it with NaN\n",
    "    test_df['TARGET'] = np.nan\n",
    "\n",
    "    # Combine train and test datasets\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = pd.concat([df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "\n",
    "    # Categorical features with One-Hot encode (excluding 'Type_data')\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "\n",
    "    # Assurer que 'Type_data' est bien une colonne catégorielle\n",
    "    df['type_data'] = df['type_data'].astype('category')\n",
    "\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    # Clean up\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/bureau.csv', sep=',', encoding='ISO-8859-1')\n",
    "    bb = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/bureau_balance.csv', sep=',', encoding='ISO-8859-1')\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/previous_application.csv', sep=',', encoding='ISO-8859-1')\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos= pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/POS_CASH_balance.csv', sep=',', encoding='ISO-8859-1')\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/installments_payments.csv', sep=',', encoding='ISO-8859-1')\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc= pd.read_csv('/Users/amira/Documents/OPC/Projet8/data/credit_card_balance.csv', sep=',', encoding='ISO-8859-1')\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n"
     ]
    }
   ],
   "source": [
    "train_test_df = application_train_test()           # application_train.csv et application_test.csv\n",
    "bureau_agg_df = bureau_and_balance()               # bureau.csv et bureau_balance.csv\n",
    "prev_app_agg_df = previous_applications()          # previous_application.csv\n",
    "pos_cash_agg_df = pos_cash()                       # POS_CASH_balance.csv\n",
    "installments_agg_df = installments_payments()      # installments_payments.csv\n",
    "credit_card_agg_df = credit_card_balance()         # credit_card_balance.csv\n",
    "\n",
    "# Le DataFrame principal est `train_test_df`, et nous fusionnons chaque ensemble basé sur `SK_ID_CURR`.\n",
    "train_test_df = train_test_df.merge(bureau_agg_df, on='SK_ID_CURR', how='left')\n",
    "train_test_df = train_test_df.merge(prev_app_agg_df, on='SK_ID_CURR', how='left')\n",
    "train_test_df = train_test_df.merge(pos_cash_agg_df, on='SK_ID_CURR', how='left')\n",
    "train_test_df = train_test_df.merge(installments_agg_df, on='SK_ID_CURR', how='left')\n",
    "train_test_df = train_test_df.merge(credit_card_agg_df, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer le DataFrame selon la colonne 'Type_data'\n",
    "train_df = train_test_df[train_test_df['type_data'] == 'train']\n",
    "train_df = train_df.drop(columns=['type_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables sélectionnées : ['TARGET', 'CC_CNT_DRAWINGS_ATM_CURRENT_MEAN', 'CC_CNT_DRAWINGS_CURRENT_MAX', 'BURO_DAYS_CREDIT_MEAN', 'CC_AMT_BALANCE_MEAN', 'DAYS_BIRTH', 'PREV_NAME_CONTRACT_STATUS_Refused_MEAN', 'BURO_CREDIT_ACTIVE_Active_MEAN', 'DAYS_EMPLOYED', 'REFUSED_DAYS_DECISION_MAX', 'CC_AMT_BALANCE_MIN', 'ACTIVE_DAYS_CREDIT_MEAN', 'CC_CNT_DRAWINGS_ATM_CURRENT_MAX', 'CC_MONTHS_BALANCE_MEAN', 'BURO_STATUS_1_MEAN_MEAN', 'CC_CNT_DRAWINGS_ATM_CURRENT_VAR', 'REGION_RATING_CLIENT_W_CITY', 'CC_AMT_DRAWINGS_CURRENT_MEAN', 'NAME_INCOME_TYPE_Working', 'PREV_NAME_PRODUCT_TYPE_walk-in_MEAN', 'PREV_CODE_REJECT_REASON_SCOFR_MEAN', 'DAYS_LAST_PHONE_CHANGE', 'APPROVED_DAYS_DECISION_MIN', 'DAYS_ID_PUBLISH', 'REG_CITY_NOT_WORK_CITY', 'REFUSED_HOUR_APPR_PROCESS_START_MIN', 'CODE_GENDER', 'BURO_STATUS_C_MEAN_MEAN', 'NAME_EDUCATION_TYPE_Higher education', 'PREV_NAME_CONTRACT_STATUS_Approved_MEAN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/0lf4cqg97cq6qg1y7t6fp0sw0000gn/T/ipykernel_4248/883333678.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_2['SK_ID_CURR'] = train_df['SK_ID_CURR']\n"
     ]
    }
   ],
   "source": [
    "# Calculer les corrélations avec la variable TARGET\n",
    "corr_with_target = train_df.corr()['TARGET'].sort_values(ascending=False)\n",
    "\n",
    "# Filtrer les variables ayant une corrélation significative avec TARGET\n",
    "threshold = 0.05  \n",
    "significant_vars = corr_with_target[abs(corr_with_target) > threshold].index.tolist()\n",
    "\n",
    "# Créer un sous-ensemble du DataFrame avec ces variables\n",
    "df_significant = train_df[significant_vars]\n",
    "\n",
    "# Calculer la matrice de corrélation pour ces variables\n",
    "corr_matrix = df_significant.corr().abs()\n",
    "\n",
    "# Supprimer les variables corrélées entre elles \n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Trouver les variables ayant une corrélation supérieure au seuil\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.7)]\n",
    "\n",
    "# Supprimer les variables corrélées entre elles\n",
    "df_reduced = df_significant.drop(columns=to_drop)\n",
    "\n",
    "# Créer un DataFrame sans valeurs manquantes pour le calcul du VIF\n",
    "X = df_reduced.dropna().assign(constant=1)\n",
    "\n",
    "# Calculer les VIF pour chaque variable sur les données sans valeurs manquantes\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Filtrer les variables ayant un VIF élevé \n",
    "final_vars = vif_data[vif_data['VIF'] < 5]['feature'].tolist()\n",
    "\n",
    "# Supprimer la constante du résultat final si présente\n",
    "if 'constant' in final_vars:\n",
    "    final_vars.remove('constant')\n",
    "\n",
    "# Les variables finales sélectionnées\n",
    "print(\"Variables sélectionnées :\", final_vars)\n",
    "\n",
    "# Créer un dataframe qui regroupe les variables sélectionnées\n",
    "train_df_2 = train_df[final_vars]\n",
    "\n",
    "# Ajouter SK_ID_CURR au DataFrame final\n",
    "if 'SK_ID_CURR' in train_df.columns:\n",
    "    train_df_2['SK_ID_CURR'] = train_df['SK_ID_CURR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>BURO_DAYS_CREDIT_MEAN</th>\n",
       "      <th>CC_AMT_BALANCE_MEAN</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>PREV_NAME_CONTRACT_STATUS_Refused_MEAN</th>\n",
       "      <th>BURO_CREDIT_ACTIVE_Active_MEAN</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>REFUSED_DAYS_DECISION_MAX</th>\n",
       "      <th>...</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>REFUSED_HOUR_APPR_PROCESS_START_MIN</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>BURO_STATUS_C_MEAN_MEAN</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>PREV_NAME_CONTRACT_STATUS_Approved_MEAN</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-874.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175426</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1400.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-867.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19005</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3039.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145570</td>\n",
       "      <td>0.681632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-867.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-7921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459677</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744026</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>456253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1104.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4786.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514163</td>\n",
       "      <td>0.661024</td>\n",
       "      <td>456254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1089.454545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16856</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-1262.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>0.113922</td>\n",
       "      <td>456255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TARGET  CC_CNT_DRAWINGS_ATM_CURRENT_MEAN  CC_CNT_DRAWINGS_CURRENT_MAX  \\\n",
       "0          1.0                               NaN                          NaN   \n",
       "1          0.0                               NaN                          NaN   \n",
       "2          0.0                               NaN                          NaN   \n",
       "3          0.0                               NaN                          0.0   \n",
       "4          0.0                               NaN                          NaN   \n",
       "...        ...                               ...                          ...   \n",
       "307506     0.0                               NaN                          NaN   \n",
       "307507     0.0                               NaN                          NaN   \n",
       "307508     0.0                               NaN                          NaN   \n",
       "307509     1.0                               NaN                          NaN   \n",
       "307510     0.0                               NaN                          NaN   \n",
       "\n",
       "        BURO_DAYS_CREDIT_MEAN  CC_AMT_BALANCE_MEAN  DAYS_BIRTH  \\\n",
       "0                 -874.000000                  NaN       -9461   \n",
       "1                -1400.750000                  NaN      -16765   \n",
       "2                 -867.000000                  NaN      -19046   \n",
       "3                         NaN                  0.0      -19005   \n",
       "4                -1149.000000                  NaN      -19932   \n",
       "...                       ...                  ...         ...   \n",
       "307506                    NaN                  NaN       -9327   \n",
       "307507                    NaN                  NaN      -20775   \n",
       "307508            -867.500000                  NaN      -14966   \n",
       "307509           -1104.000000                  NaN      -11961   \n",
       "307510           -1089.454545                  NaN      -16856   \n",
       "\n",
       "        PREV_NAME_CONTRACT_STATUS_Refused_MEAN  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                     0.111111   \n",
       "4                                     0.000000   \n",
       "...                                        ...   \n",
       "307506                                0.000000   \n",
       "307507                                0.000000   \n",
       "307508                                0.000000   \n",
       "307509                                0.000000   \n",
       "307510                                0.250000   \n",
       "\n",
       "        BURO_CREDIT_ACTIVE_Active_MEAN  DAYS_EMPLOYED  \\\n",
       "0                             0.250000         -637.0   \n",
       "1                             0.250000        -1188.0   \n",
       "2                             0.000000         -225.0   \n",
       "3                                  NaN        -3039.0   \n",
       "4                             0.000000        -3038.0   \n",
       "...                                ...            ...   \n",
       "307506                             NaN         -236.0   \n",
       "307507                             NaN            NaN   \n",
       "307508                        0.500000        -7921.0   \n",
       "307509                        0.000000        -4786.0   \n",
       "307510                        0.454545        -1262.0   \n",
       "\n",
       "        REFUSED_DAYS_DECISION_MAX  ...  REG_CITY_NOT_WORK_CITY  \\\n",
       "0                             NaN  ...                       0   \n",
       "1                             NaN  ...                       0   \n",
       "2                             NaN  ...                       0   \n",
       "3                          -181.0  ...                       0   \n",
       "4                             NaN  ...                       1   \n",
       "...                           ...  ...                     ...   \n",
       "307506                        NaN  ...                       0   \n",
       "307507                        NaN  ...                       0   \n",
       "307508                        NaN  ...                       1   \n",
       "307509                        NaN  ...                       1   \n",
       "307510                     -171.0  ...                       1   \n",
       "\n",
       "        REFUSED_HOUR_APPR_PROCESS_START_MIN  CODE_GENDER  \\\n",
       "0                                       NaN            0   \n",
       "1                                       NaN            1   \n",
       "2                                       NaN            0   \n",
       "3                                      15.0            1   \n",
       "4                                       NaN            0   \n",
       "...                                     ...          ...   \n",
       "307506                                  NaN            0   \n",
       "307507                                  NaN            1   \n",
       "307508                                  NaN            1   \n",
       "307509                                  NaN            1   \n",
       "307510                                 14.0            1   \n",
       "\n",
       "        BURO_STATUS_C_MEAN_MEAN  NAME_EDUCATION_TYPE_Higher education  \\\n",
       "0                      0.175426                                     0   \n",
       "1                           NaN                                     1   \n",
       "2                           NaN                                     0   \n",
       "3                           NaN                                     0   \n",
       "4                           NaN                                     0   \n",
       "...                         ...                                   ...   \n",
       "307506                      NaN                                     0   \n",
       "307507                      NaN                                     0   \n",
       "307508                 0.459677                                     1   \n",
       "307509                 0.783784                                     0   \n",
       "307510                 0.645601                                     1   \n",
       "\n",
       "        PREV_NAME_CONTRACT_STATUS_Approved_MEAN  EXT_SOURCE_1  EXT_SOURCE_2  \\\n",
       "0                                      1.000000      0.083037      0.262949   \n",
       "1                                      1.000000      0.311267      0.622246   \n",
       "2                                      1.000000           NaN      0.555912   \n",
       "3                                      0.555556           NaN      0.650442   \n",
       "4                                      1.000000           NaN      0.322738   \n",
       "...                                         ...           ...           ...   \n",
       "307506                                 1.000000      0.145570      0.681632   \n",
       "307507                                 1.000000           NaN      0.115992   \n",
       "307508                                 1.000000      0.744026      0.535722   \n",
       "307509                                 1.000000           NaN      0.514163   \n",
       "307510                                 0.750000      0.734460      0.708569   \n",
       "\n",
       "        EXT_SOURCE_3  SK_ID_CURR  \n",
       "0           0.139376      100002  \n",
       "1                NaN      100003  \n",
       "2           0.729567      100004  \n",
       "3                NaN      100006  \n",
       "4                NaN      100007  \n",
       "...              ...         ...  \n",
       "307506           NaN      456251  \n",
       "307507           NaN      456252  \n",
       "307508      0.218859      456253  \n",
       "307509      0.661024      456254  \n",
       "307510      0.113922      456255  \n",
       "\n",
       "[307511 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_columns = train_df_2.select_dtypes(include=[np.number]).columns\n",
    "quantitative_columns = quantitative_columns.drop('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le jeu de test a été enregistré sous 'data_illustration_dashboard.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Supposons que train_df_2 contient déjà la variable 'TARGET' et 'SK_ID_CURR'\n",
    "\n",
    "# Faire le split directement sur le DataFrame complet avec 'TARGET'\n",
    "df_train, test_df = train_test_split(train_df_2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensuite, on sépare les colonnes après le split\n",
    "X_test = test_df.drop(columns='TARGET')\n",
    "y_test = test_df['TARGET']\n",
    "\n",
    "# Sélectionner uniquement les colonnes quantitatives, en excluant SK_ID_CURR\n",
    "quantitative_columns = X_test.select_dtypes(include=[np.number]).columns\n",
    "quantitative_columns = quantitative_columns.drop('SK_ID_CURR', errors='ignore')\n",
    "\n",
    "# Initialiser l'imputer pour remplacer NaN par 0\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "# Fit l'imputer sur les données d'entraînement\n",
    "imputer.fit(df_train[quantitative_columns])\n",
    "\n",
    "# Appliquer l'imputer sur les colonnes quantitatives des jeux de données de test\n",
    "X_test[quantitative_columns] = imputer.transform(X_test[quantitative_columns])\n",
    "\n",
    "# Standardiser les données avec MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit le scaler sur les colonnes quantitatives des données d'entraînement\n",
    "scaler.fit(df_train[quantitative_columns])\n",
    "\n",
    "# **Appliquer la standardisation uniquement sur les colonnes quantitatives**\n",
    "X_test_scaled = scaler.transform(X_test[quantitative_columns])\n",
    "\n",
    "# Créer un DataFrame à partir de X_test_scaled\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=quantitative_columns)\n",
    "\n",
    "# Ajouter la colonne 'SK_ID_CURR' sans prétraitement\n",
    "X_test_df['SK_ID_CURR'] = test_df['SK_ID_CURR'].values\n",
    "\n",
    "# Ajouter la colonne 'TARGET' à partir de test_df\n",
    "X_test_df['TARGET'] = test_df['TARGET'].values\n",
    "\n",
    "# Renommer les colonnes si nécessaire\n",
    "X_test_df.rename(columns={\n",
    "    'PREV_NAME_PRODUCT_TYPE_walk-in_MEAN': 'PREV_NAME_PRODUCT_TYPE_walk_in_MEAN',\n",
    "    'NAME_EDUCATION_TYPE_Higher education': 'NAME_EDUCATION_TYPE_Higher_education'\n",
    "}, inplace=True)\n",
    "\n",
    "# Enregistrer les 5 premières lignes dans un fichier CSV\n",
    "X_test_df.head(5).to_csv('data_illustration_dashboard.csv', index=False)\n",
    "\n",
    "print(\"Le jeu de test a été enregistré sous 'data_illustration_dashboard.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_illustration_dashboard.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>BURO_DAYS_CREDIT_MEAN</th>\n",
       "      <th>CC_AMT_BALANCE_MEAN</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>PREV_NAME_CONTRACT_STATUS_Refused_MEAN</th>\n",
       "      <th>BURO_CREDIT_ACTIVE_Active_MEAN</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>REFUSED_DAYS_DECISION_MAX</th>\n",
       "      <th>CC_AMT_BALANCE_MIN</th>\n",
       "      <th>...</th>\n",
       "      <th>REFUSED_HOUR_APPR_PROCESS_START_MIN</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>BURO_STATUS_C_MEAN_MEAN</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher_education</th>\n",
       "      <th>PREV_NAME_CONTRACT_STATUS_Approved_MEAN</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608878</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.672604</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.957459</td>\n",
       "      <td>0.558562</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.705732</td>\n",
       "      <td>0.707479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>384575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.711978</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.589121</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.936300</td>\n",
       "      <td>0.741438</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444220</td>\n",
       "      <td>0.497486</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>214010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.705966</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.412740</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.964326</td>\n",
       "      <td>0.851027</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.462302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.547108</td>\n",
       "      <td>0.621942</td>\n",
       "      <td>0.231648</td>\n",
       "      <td>142232</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171458</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.315840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610205</td>\n",
       "      <td>1.000685</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015547</td>\n",
       "      <td>0.811136</td>\n",
       "      <td>0.685538</td>\n",
       "      <td>389171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583961</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.276325</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.595205</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.683325</td>\n",
       "      <td>0.655778</td>\n",
       "      <td>0.710063</td>\n",
       "      <td>283617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CC_CNT_DRAWINGS_ATM_CURRENT_MEAN  CC_CNT_DRAWINGS_CURRENT_MAX  \\\n",
       "0                             0.000                     0.000000   \n",
       "1                             0.025                     0.054545   \n",
       "2                             0.000                     0.000000   \n",
       "3                             0.000                     0.000000   \n",
       "4                             0.000                     0.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_MEAN  CC_AMT_BALANCE_MEAN  DAYS_BIRTH  \\\n",
       "0               0.608878             0.003145    0.672604   \n",
       "1               0.711978             0.031674    0.589121   \n",
       "2               0.705966             0.003145    0.412740   \n",
       "3               0.171458             0.003145    0.315840   \n",
       "4               0.583961             0.003145    0.276325   \n",
       "\n",
       "   PREV_NAME_CONTRACT_STATUS_Refused_MEAN  BURO_CREDIT_ACTIVE_Active_MEAN  \\\n",
       "0                                0.600000                        0.428571   \n",
       "1                                0.166667                        0.400000   \n",
       "2                                0.142857                        0.500000   \n",
       "3                                0.000000                        0.000000   \n",
       "4                                0.333333                        0.333333   \n",
       "\n",
       "   DAYS_EMPLOYED  REFUSED_DAYS_DECISION_MAX  CC_AMT_BALANCE_MIN  ...  \\\n",
       "0       0.957459                   0.558562            0.230011  ...   \n",
       "1       0.936300                   0.741438            0.230011  ...   \n",
       "2       0.964326                   0.851027            0.230011  ...   \n",
       "3       0.610205                   1.000685            0.230011  ...   \n",
       "4       0.938310                   0.595205            0.230011  ...   \n",
       "\n",
       "   REFUSED_HOUR_APPR_PROCESS_START_MIN  CODE_GENDER  BURO_STATUS_C_MEAN_MEAN  \\\n",
       "0                             0.478261          0.0                 0.153917   \n",
       "1                             0.260870          0.5                 0.000000   \n",
       "2                             0.652174          0.5                 0.462302   \n",
       "3                             0.000000          0.5                 0.000000   \n",
       "4                             0.434783          0.0                 0.000000   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Higher_education  \\\n",
       "0                                   0.0   \n",
       "1                                   1.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   PREV_NAME_CONTRACT_STATUS_Approved_MEAN  EXT_SOURCE_1  EXT_SOURCE_2  \\\n",
       "0                                 0.400000      0.705732      0.707479   \n",
       "1                                 0.833333      0.444220      0.497486   \n",
       "2                                 0.428571      0.547108      0.621942   \n",
       "3                                 1.000000     -0.015547      0.811136   \n",
       "4                                 0.555556      0.683325      0.655778   \n",
       "\n",
       "   EXT_SOURCE_3  SK_ID_CURR  TARGET  \n",
       "0      0.000000      384575     0.0  \n",
       "1      0.794687      214010     0.0  \n",
       "2      0.231648      142232     0.0  \n",
       "3      0.685538      389171     0.0  \n",
       "4      0.710063      283617     0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
